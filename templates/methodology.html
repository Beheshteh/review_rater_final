<!DOCTYPE html>

<html lang="en-us">

<head>
  <meta charset="UTF-8">
  <title>Yelp Review Analysis</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" 
        integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <link rel="stylesheet" href="../static/css/style.css">
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>  
    
</head>

<body>
  <!--Navbar-->

  <nav class="navbar navbar-inverse">
          <div class="container-fluid">
            <button class="navbar-header"><a href="/">Home</a></button>
            
            <div class="btn-group navbar-right">
                <button class="navbar-header"><a href="/methodology">Methodology</a></button>
                <button class="navbar-header"><a href="/collection">Review Collection</a></button>   
                
            </div>  
          </div><!-- /.container-fluid -->
        </nav>
    </div><!-- /.container-fluid -->
  </nav>

  <div class="container">
    <br>
    <h3>Source of Data</h3>
    <p> The data used in this project was downloaded from 
       <a class= "data" href="https://www.kaggle.com/yelp-dataset/yelp-dataset/data">Kaggle Yelp Dataset</a>
        (yelp_business.csv and yelp_review.csv). As you can see this data skewed geographically. </p>

    <img  id="mainpicture" src="../static/img/dashboardmap.PNG" alt="Map of data">    
         
     <h3>Data Screening and selection</h3>
     <p>The data set provided with Yelp was included 7 files and 5.53 GB of data. For the purpose of our project we 
       limited our data to resturants, bar and other food related categories. Also we slice our data based on the users
        who wrote 5o to 100 reviews. </p>

     <table>
        <tr>
            <th>Column  </th>
            <th>  Entire dataset  </th>
            <th>  Resturants/ bars/ food  </th>
            <th>  Users with 50 to 100 reviews</th>
        </tr>
        <tr>
            <td>Businesesses</td>
            <td>174,567</td>
            <td>72,103</td>
            <td>50,642</td>
        </tr>
        <tr>
            <td>users</td>
            <td>1,326,101</td>
            <td>960,561</td>
            <td>4,676</td>
        </tr>
        <tr>
            <td>Reviews</td>
            <td>5,261,668</td>
            <td>3,636,641</td>
            <td>323,100</td>
        </tr>
        <tr>
            <td>Files</td>
            <td>7</td>
            <td>2</td>
            <td>1</td>
        </tr>
        <tr>
            <td>Size</td>
            <td>5.53 GB</td>
            <td>3.82 GB</td>
            <td>273 MB</td>
        </tr>
    </table>

    
    <p>We narrow the dataset based on user review's number. because as users write more reviews, the distribution of star ratings
      given become more and more normal. Below is the bar chart of distribution of rating for the users who wrote 50 to 100 reviews.</p>
    <p><img src="../static/img/export_filtered_reviews_50_100.PNG" alt="review 50_100" height="200px" width = "200px" ></p>
  
  
    <strong><h3>Naive Bayes Model</h3></strong>  
    <img src="" >

    <p>We have hunderds of thousands of data points and quite a few variables in our training data set. In such situation,
     ‘Naive Bayes‘, can be extremely fast relative to other classification algorithms. It works on Bayes theorem of probability 
     to predict the class of unknown data set.</p>

     <p>In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to 
       the presence of any other feature. Even if these features depend on each other or upon the existence of the other features, 
       all of these properties independently contribute to the probability that this fruit is an apple and that is why it is known as ‘Naive’.
        
        Naive Bayes model is easy to build and particularly useful for very large data sets. Along with simplicity, 
        Naive Bayes is known to outperform even highly sophisticated classification methods.</p>

     

     <strong><h3>Natural Network Model</h3></strong>
    <p>We used a Neural Network Model and tokenized text reviews to classify them in a 1-5 rating.
       Traditional Neural Networks use each instance of information fed in order to produce an output:</p>
       <img id="datapicture" src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png">
    <p>This is an issue as humans do not rate a review on a per word basis. We use context in our sentences to
       form opinions and sentiment. To compensate for that, we added in a LSTM layer. Long Short-Term Memory 
       networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies.</p>   
       
       <img id="datapicture" src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png">
    <p>The core line (black horizontal top line) uses information selected from previous layers and uses that “context”
       to give a classification output (ht). </p>

           
     
        
  </div>
  
</body>
</html>
      